{"cells":[{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:04:14.467187Z","iopub.status.busy":"2023-07-15T12:04:14.466822Z","iopub.status.idle":"2023-07-15T12:04:21.697103Z","shell.execute_reply":"2023-07-15T12:04:21.696060Z","shell.execute_reply.started":"2023-07-15T12:04:14.467156Z"}},"source":["# **TRAIN LLE_UNET FOR IMAGE DENOISING**                    "]},{"cell_type":"markdown","metadata":{},"source":["**Dataset - smartphone-image-denoising-dataset \n","from Kaggle**"]},{"cell_type":"markdown","metadata":{},"source":["https://www.kaggle.com/code/pamuduranasinghe/train-lle-unet-for-image-denoisng\n","\n","This can be directly use from the Kaggle with its dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:09.318027Z","iopub.status.busy":"2023-07-15T12:27:09.317658Z","iopub.status.idle":"2023-07-15T12:27:09.325865Z","shell.execute_reply":"2023-07-15T12:27:09.324790Z","shell.execute_reply.started":"2023-07-15T12:27:09.317997Z"},"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import sys\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import math\n","import random\n","\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Activation, Concatenate, GlobalAveragePooling2D, Multiply,GlobalMaxPooling2D\n","from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, Conv2DTranspose, Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications.vgg16 import VGG16"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:09.328554Z","iopub.status.busy":"2023-07-15T12:27:09.327902Z","iopub.status.idle":"2023-07-15T12:27:09.351830Z","shell.execute_reply":"2023-07-15T12:27:09.350890Z","shell.execute_reply.started":"2023-07-15T12:27:09.328503Z"},"trusted":true},"outputs":[],"source":["# set Radndom Seed\n","SEED = 0\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","tf.config.run_functions_eagerly(True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:09.356651Z","iopub.status.busy":"2023-07-15T12:27:09.356296Z","iopub.status.idle":"2023-07-15T12:27:09.361702Z","shell.execute_reply":"2023-07-15T12:27:09.360700Z","shell.execute_reply.started":"2023-07-15T12:27:09.356614Z"},"trusted":true},"outputs":[],"source":["# Avoid OOM errors by setting GPU Memory Consumption Growth\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","for gpu in gpus:\n","    tf.config.experimental.set_memory_growth(gpu, True)"]},{"cell_type":"markdown","metadata":{},"source":["**Padding mechanism to work with images of any width and height**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:09.365620Z","iopub.status.busy":"2023-07-15T12:27:09.364695Z","iopub.status.idle":"2023-07-15T12:27:09.375574Z","shell.execute_reply":"2023-07-15T12:27:09.374478Z","shell.execute_reply.started":"2023-07-15T12:27:09.365529Z"},"trusted":true},"outputs":[],"source":["def padding_calc(input_dim,multiplier=32):\n","    return math.ceil(input_dim/multiplier)*multiplier - input_dim\n","\n","# Add Padding\n","def pad_image(image,mood = \"center_padding\"):\n","    img_h = image.shape[0]\n","    img_w = image.shape[1]\n","  \n","    pad_y = padding_calc(img_h)\n","    pad_x = padding_calc(img_w)\n","    \n","    if mood == \"center_padding\":\n","        pad_y2 = pad_y//2\n","        pad_x2 = pad_x//2\n","\n","        padded_img = image.copy()\n","        if pad_y%2 != 0:\n","            padded_img = np.pad(image, ((pad_y2, pad_y2+1), (pad_x2, pad_x2), (0, 0)), mode='constant')\n","        if pad_x%2 != 0:\n","            padded_img = np.pad(image, ((pad_y2, pad_y2), (pad_x2, pad_x2+1), (0, 0)), mode='constant')\n","        if (pad_y%2 == 0) & (pad_x%2 == 0):\n","            padded_img = np.pad(image, ((pad_y2, pad_y2), (pad_x2, pad_x2), (0, 0)), mode='constant')\n","\n","    elif mood == \"corner_padding\":\n","        padded_img = np.pad(image, ((0, pad_y), (0, pad_x), (0, 0)), mode='constant')\n","    return padded_img\n","\n","# Remove Padding\n","def inverse_padding(pad_image,image_dim,pad_method=\"center_padding\"):\n","  pad_img_height = pad_image.shape[0]\n","  pad_img_width = pad_image.shape[1]\n","  \n","  img_height = image_dim[0]\n","  img_width = image_dim[1]\n","  \n","  if pad_method == \"center_padding\":\n","    pad_y1 = (pad_img_height - img_height)//2\n","    if pad_y1*2 == (pad_img_height - img_height):pad_y2 = pad_y1\n","    else: pad_y2 = pad_y1+1\n","\n","    pad_x1 = (pad_img_width - img_width)//2\n","    if pad_x1*2 == (pad_img_width - img_width):pad_x2 = pad_x1\n","    else: pad_x2 = pad_x1+1\n","    extract_image = pad_image[pad_y1:pad_img_height-pad_y2,pad_x1:pad_img_width-pad_x2]\n","  \n","  if pad_method == \"corner_padding\":\n","    extract_image = pad_image[0:img_height,0:img_width]\n","\n"," \n","  return extract_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:09.377812Z","iopub.status.busy":"2023-07-15T12:27:09.377102Z","iopub.status.idle":"2023-07-15T12:27:09.386113Z","shell.execute_reply":"2023-07-15T12:27:09.384937Z","shell.execute_reply.started":"2023-07-15T12:27:09.377779Z"},"trusted":true},"outputs":[],"source":["## test image padding mechanism\n","test_H = 300\n","test_W = 533\n","test_image = np.zeros((test_H, test_W, 3), dtype=np.uint8)\n","img_pad = pad_image(test_image,'center_padding')\n","print(test_image.shape,img_pad.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:09.388134Z","iopub.status.busy":"2023-07-15T12:27:09.387798Z","iopub.status.idle":"2023-07-15T12:27:09.393144Z","shell.execute_reply":"2023-07-15T12:27:09.392170Z","shell.execute_reply.started":"2023-07-15T12:27:09.388101Z"},"trusted":true},"outputs":[],"source":["data_path = r'/kaggle/input/smartphone-image-denoising-dataset/SIDD_Small_sRGB_Only/Data'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:09.395443Z","iopub.status.busy":"2023-07-15T12:27:09.394447Z","iopub.status.idle":"2023-07-15T12:27:09.479222Z","shell.execute_reply":"2023-07-15T12:27:09.478179Z","shell.execute_reply.started":"2023-07-15T12:27:09.395407Z"},"trusted":true},"outputs":[],"source":["gt_image_paths    = []\n","noisy_image_paths = []\n","img_folder_names  = os.listdir(data_path)\n","\n","for img_folder_name in img_folder_names:\n","    img_names = os.listdir(os.path.join(data_path,img_folder_name))\n","    for img_name in img_names:\n","        img_label = img_name.split(\"_\")[0]\n","        img_path = os.path.join(data_path,img_folder_name,img_name)\n","        if img_label == \"GT\":\n","            gt_image_paths.append(img_path)\n","        elif img_label == \"NOISY\":\n","            noisy_image_paths.append(img_path)\n","        else:\n","            print(f'{img_path} NOT GT OR NOISY')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:09.480924Z","iopub.status.busy":"2023-07-15T12:27:09.480473Z","iopub.status.idle":"2023-07-15T12:27:09.487740Z","shell.execute_reply":"2023-07-15T12:27:09.486586Z","shell.execute_reply.started":"2023-07-15T12:27:09.480890Z"},"trusted":true},"outputs":[],"source":["gt_image_paths    = sorted(gt_image_paths)\n","noisy_image_paths = sorted(noisy_image_paths)\n","\n","print(f'N_GROUND TRUTH IMAGES : {len(gt_image_paths)}')\n","print(f'N_NOISY IMAGES : {len(noisy_image_paths)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:09.493391Z","iopub.status.busy":"2023-07-15T12:27:09.492676Z","iopub.status.idle":"2023-07-15T12:27:09.501347Z","shell.execute_reply":"2023-07-15T12:27:09.500304Z","shell.execute_reply.started":"2023-07-15T12:27:09.493353Z"},"trusted":true},"outputs":[],"source":["def split_data(image_paths, ground_truth_paths, train_ratio, val_ratio, test_ratio):        \n","    data_pairs = list(zip(image_paths, ground_truth_paths))\n","    random.shuffle(data_pairs)\n","    \n","    # Calculate the number of samples for each split\n","    total_samples = len(data_pairs)\n","    train_samples = int(train_ratio * total_samples)\n","    val_samples = int(val_ratio * total_samples)\n","    test_samples = total_samples - train_samples - val_samples\n","    \n","    # Split the data into training, validation, and testing sets\n","    train_data = data_pairs[:train_samples]\n","    val_data = data_pairs[train_samples:train_samples+val_samples]\n","    test_data = data_pairs[train_samples+val_samples:]\n","    \n","    # Unzip the pairs into separate lists for images and ground truth\n","    train_x, train_y = zip(*train_data)\n","    val_x, val_y = zip(*val_data)\n","    test_x, test_y = zip(*test_data)\n","    \n","    return train_x, train_y, val_x, val_y, test_x, test_y"]},{"cell_type":"markdown","metadata":{},"source":["**Split data into Train, Validation and Test**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:09.503421Z","iopub.status.busy":"2023-07-15T12:27:09.503020Z","iopub.status.idle":"2023-07-15T12:27:09.512737Z","shell.execute_reply":"2023-07-15T12:27:09.511773Z","shell.execute_reply.started":"2023-07-15T12:27:09.503387Z"},"trusted":true},"outputs":[],"source":["train_ratio = 0.8  \n","val_ratio   = 0.1  \n","test_ratio  = 0.1\n","\n","train_x_paths, train_y_paths, val_x_paths, val_y_paths, test_x_paths, test_y_paths = split_data(gt_image_paths, noisy_image_paths, train_ratio, val_ratio, test_ratio)\n","train_x_paths = sorted(train_x_paths)\n","train_y_paths = sorted(train_y_paths)\n","val_x_paths = sorted(val_x_paths)\n","val_y_paths = sorted(val_y_paths)\n","test_x_paths = sorted(test_x_paths)\n","test_y_paths = sorted(test_y_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:09.514582Z","iopub.status.busy":"2023-07-15T12:27:09.514040Z","iopub.status.idle":"2023-07-15T12:27:09.526578Z","shell.execute_reply":"2023-07-15T12:27:09.525575Z","shell.execute_reply.started":"2023-07-15T12:27:09.514488Z"},"trusted":true},"outputs":[],"source":["print(f'X_train : {len(train_x_paths)}')\n","print(f'Y_train : {len(train_y_paths)}')\n","print(f'X_val   : {len(val_x_paths)}')\n","print(f'Y_val   : {len(val_y_paths)}')\n","print(f'X_test  : {len(test_x_paths)}')\n","print(f'Y_test  : {len(test_y_paths)}')"]},{"cell_type":"markdown","metadata":{},"source":["**Create DataLoading functions for Load the Kaggle SIDD Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:09.528649Z","iopub.status.busy":"2023-07-15T12:27:09.528224Z","iopub.status.idle":"2023-07-15T12:27:09.536606Z","shell.execute_reply":"2023-07-15T12:27:09.535668Z","shell.execute_reply.started":"2023-07-15T12:27:09.528617Z"},"trusted":true},"outputs":[],"source":["@tf.function\n","def load_image_file(file_path):\n","    file_path = file_path.numpy().decode(\"utf-8\")\n","    img = cv2.imread(file_path)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    img = cv2.resize(img,(1024,1024))\n","    # img = cv2.resize(img,(0,0),fx=0.5, fy=0.5)\n","    preprocess_img = pad_image(img)\n","    preprocess_img = preprocess_img/255\n","    return img\n","\n","def image_dataset(image_list):\n","    files = tf.data.Dataset.from_tensor_slices(image_list)\n","    dataset = files.map(lambda x: tf.py_function(load_image_file, [x], tf.float32))\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:09.538459Z","iopub.status.busy":"2023-07-15T12:27:09.538117Z","iopub.status.idle":"2023-07-15T12:27:09.575395Z","shell.execute_reply":"2023-07-15T12:27:09.574462Z","shell.execute_reply.started":"2023-07-15T12:27:09.538427Z"},"trusted":true},"outputs":[],"source":["train_x = image_dataset(list(train_x_paths))\n","train_y = image_dataset(list(train_y_paths))\n","\n","BATCH_SIZE = 2\n","\n","# combine input and output\n","train = tf.data.Dataset.zip((train_x, train_y))\n","# train = train.take(100)\n","# train = train.shuffle(100)\n","train = train.batch(BATCH_SIZE)\n","train.prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:09.577027Z","iopub.status.busy":"2023-07-15T12:27:09.576671Z","iopub.status.idle":"2023-07-15T12:27:09.603778Z","shell.execute_reply":"2023-07-15T12:27:09.602704Z","shell.execute_reply.started":"2023-07-15T12:27:09.576982Z"},"trusted":true},"outputs":[],"source":["val_x = image_dataset(list(val_x_paths))\n","val_y = image_dataset(list(val_y_paths))\n","\n","# combine input and output\n","val = tf.data.Dataset.zip((val_x, val_y))\n","# train = train.shuffle(100)\n","val = val.batch(BATCH_SIZE)\n","val.prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:09.607083Z","iopub.status.busy":"2023-07-15T12:27:09.606458Z","iopub.status.idle":"2023-07-15T12:27:10.124769Z","shell.execute_reply":"2023-07-15T12:27:10.123677Z","shell.execute_reply.started":"2023-07-15T12:27:09.607048Z"},"trusted":true},"outputs":[],"source":["test_x = image_dataset(list(test_x_paths))\n","test_y = image_dataset(list(test_y_paths))\n","\n","# combine input and output\n","test = tf.data.Dataset.zip((test_x, test_y))\n","# train = train.shuffle(100)\n","test = test.batch(BATCH_SIZE)\n","test.prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:10.126880Z","iopub.status.busy":"2023-07-15T12:27:10.126503Z","iopub.status.idle":"2023-07-15T12:27:10.131451Z","shell.execute_reply":"2023-07-15T12:27:10.130559Z","shell.execute_reply.started":"2023-07-15T12:27:10.126846Z"},"trusted":true},"outputs":[],"source":["# sample = train.take(1)\n","# train_sample = sample.as_numpy_iterator()\n","# res = train_sample.next()\n","# print(len(res))\n","\n","# res_low_1 = res[0][0]\n","# res_high_1 = res[1][0]\n","\n","# fig, axs = plt.subplots(ncols=2);\n","# axs[0].imshow(res_low_1);\n","# axs[1].imshow(res_high_1);"]},{"cell_type":"markdown","metadata":{},"source":["# **LLE UNET**\n","[LLE UNET FULL CODE](https://github.com/pamudu123/Low_Light_Image_Enhancement)"]},{"cell_type":"markdown","metadata":{},"source":["**CBAM ATTENTION**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:10.133673Z","iopub.status.busy":"2023-07-15T12:27:10.132989Z","iopub.status.idle":"2023-07-15T12:27:10.144766Z","shell.execute_reply":"2023-07-15T12:27:10.143865Z","shell.execute_reply.started":"2023-07-15T12:27:10.133637Z"},"trusted":true},"outputs":[],"source":["def channel_attention_module(x, ratio=8):\n","    batch, _, _, channel = x.shape\n","\n","    ## Shared layers\n","    l1 = Dense(channel//ratio, activation=\"relu\", use_bias=False)\n","    l2 = Dense(channel, use_bias=False)\n","\n","    ## Global Average Pooling\n","    x1 = GlobalAveragePooling2D()(x)\n","    x1 = l1(x1)\n","    x1 = l2(x1)\n","\n","    ## Global Max Pooling\n","    x2 = GlobalMaxPooling2D()(x)\n","    x2 = l1(x2)\n","    x2 = l2(x2)\n","\n","    ## Add both the features and pass through sigmoid\n","    feats = x1 + x2\n","    feats = Activation(\"sigmoid\")(feats)\n","    feats = Multiply()([x, feats])\n","\n","    return feats\n","\n","def spatial_attention_module(x):\n","    ## Average Pooling\n","    x1 = tf.reduce_mean(x, axis=-1)\n","    x1 = tf.expand_dims(x1, axis=-1)\n","\n","    ## Max Pooling\n","    x2 = tf.reduce_max(x, axis=-1)\n","    x2 = tf.expand_dims(x2, axis=-1)\n","\n","    ## Concatenat both the features\n","    feats = Concatenate()([x1, x2])\n","    ## Conv layer\n","    feats = Conv2D(1, kernel_size=7, padding=\"same\", activation=\"sigmoid\")(feats)\n","    feats = Multiply()([x, feats])\n","\n","    return feats\n","\n","def CBAM(x):\n","    x = channel_attention_module(x)\n","    x = spatial_attention_module(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:10.146744Z","iopub.status.busy":"2023-07-15T12:27:10.146364Z","iopub.status.idle":"2023-07-15T12:27:10.160637Z","shell.execute_reply":"2023-07-15T12:27:10.159704Z","shell.execute_reply.started":"2023-07-15T12:27:10.146711Z"},"trusted":true},"outputs":[],"source":["def conv_block(input, num_filters):\n","    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    return x\n","\n","def encoder_block(input, num_filters):\n","    x = conv_block(input, num_filters)\n","    p = MaxPool2D((2, 2))(x)\n","    return x, p\n","\n","def decoder_block(input, skip_features, num_filters):\n","    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n","    x = Concatenate()([x, skip_features])\n","    x = conv_block(x, num_filters)\n","    return x\n","\n","def build_model(input_shape):\n","    inputs = Input(input_shape)\n","\n","    vgg_model = VGG16(include_top=False, weights=\"imagenet\",input_tensor=inputs)\n","    vgg_model.trainable = False\n","\n","    # Encoder\n","    s1 = vgg_model.get_layer(\"block1_conv2\").output                             ## (512 x 512)\n","    s2 = vgg_model.get_layer(\"block2_conv2\").output                             ## (256 x 256)\n","    s3 = vgg_model.get_layer(\"block3_conv3\").output                             ## (128 x 128)\n","    s4 = vgg_model.get_layer(\"block4_conv3\").output                             ## (64 x 64)\n","\n","    b1 = vgg_model.get_layer(\"block5_conv3\").output                             ## (32 x 32)\n","\n","    # Attention \n","    s1 = CBAM(s1)\n","    s2 = CBAM(s2)\n","    s3 = CBAM(s3)\n","    s4 = CBAM(s4)\n","\n","    # Decoder\n","    d1 = decoder_block(b1, s4, 512)                                             ## (64 x 64)\n","    d2 = decoder_block(d1, s3, 256)                                             ## (128 x 128)\n","    d3 = decoder_block(d2, s2, 128)                                             ## (256 x 256)\n","    d4 = decoder_block(d3, s1, 64)                                              ## (512 x 512)\n","\n","    # Output\n","    outputs = Conv2D(3, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n","\n","    model = Model(inputs, outputs, name=\"VGG_Model_LowLight_Enhancement\")\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:10.163036Z","iopub.status.busy":"2023-07-15T12:27:10.161962Z","iopub.status.idle":"2023-07-15T12:27:11.303913Z","shell.execute_reply":"2023-07-15T12:27:11.303132Z","shell.execute_reply.started":"2023-07-15T12:27:10.162998Z"},"trusted":true},"outputs":[],"source":["input_shape = (None, None, 3)\n","model = build_model(input_shape)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:11.309875Z","iopub.status.busy":"2023-07-15T12:27:11.309237Z","iopub.status.idle":"2023-07-15T12:27:11.321864Z","shell.execute_reply":"2023-07-15T12:27:11.320952Z","shell.execute_reply.started":"2023-07-15T12:27:11.309837Z"},"trusted":true},"outputs":[],"source":["print(\"trainable_weights:\", len(model.trainable_weights))\n","print(\"non_trainable_weights:\", len(model.non_trainable_weights))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:11.323472Z","iopub.status.busy":"2023-07-15T12:27:11.323143Z","iopub.status.idle":"2023-07-15T12:27:11.348833Z","shell.execute_reply":"2023-07-15T12:27:11.348077Z","shell.execute_reply.started":"2023-07-15T12:27:11.323439Z"},"trusted":true},"outputs":[],"source":["#optimizer = tf.keras.optimizers.experimental.AdamW(learning_rate=0.0001,weight_decay=0.004)\n","optimizer = tf.keras.optimizers.Adam(learning_rate=3e-4)\n","MSEloss = tf.keras.losses.MeanSquaredError()\n","\n","def charbonnier_loss(y_true, y_pred):\n","    return tf.reduce_mean(tf.sqrt(tf.square(y_true - y_pred) + tf.square(1e-3)))\n","\n","def psnr_loss_fn(y_true, y_pred):\n","    return tf.image.psnr(y_pred, y_true, max_val=1.0)\n","\n","def ssim_loss_fn(y_true,y_pred):\n","    return tf.image.ssim(y_true,y_pred,1.0)"]},{"cell_type":"markdown","metadata":{},"source":["**Tensorboard Callback**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:11.350416Z","iopub.status.busy":"2023-07-15T12:27:11.350094Z","iopub.status.idle":"2023-07-15T12:27:11.356238Z","shell.execute_reply":"2023-07-15T12:27:11.355443Z","shell.execute_reply.started":"2023-07-15T12:27:11.350384Z"},"trusted":true},"outputs":[],"source":["from keras.callbacks import ModelCheckpoint\n","\n","# tensorboard callback\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:11.357901Z","iopub.status.busy":"2023-07-15T12:27:11.357471Z","iopub.status.idle":"2023-07-15T12:27:11.371226Z","shell.execute_reply":"2023-07-15T12:27:11.370412Z","shell.execute_reply.started":"2023-07-15T12:27:11.357871Z"},"trusted":true},"outputs":[],"source":["# save_best_model_callback\n","from datetime import datetime\n","model_save_folder = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","model_save_dir = f'models/{model_save_folder}'\n","#model_save_dir = f'models'\n","\n","if not os.path.exists(model_save_dir):\n","  print(\"FOLDER CREATED\")\n","  os.makedirs(model_save_dir)\n","\n","save_best_model_checkpoint = ModelCheckpoint(model_save_dir+'/model-{epoch:03d}.hdf5',monitor='val_loss',save_best_only=True,mode='auto')"]},{"cell_type":"markdown","metadata":{},"source":["**Callback to show intermediate results of the training model.**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:11.372812Z","iopub.status.busy":"2023-07-15T12:27:11.372478Z","iopub.status.idle":"2023-07-15T12:27:11.381212Z","shell.execute_reply":"2023-07-15T12:27:11.380471Z","shell.execute_reply.started":"2023-07-15T12:27:11.372781Z"},"trusted":true},"outputs":[],"source":["def preprocess_image(img_path):\n","    img = cv2.imread(img_path)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    img = cv2.resize(img,(1024,1024))\n","    preprocess_img = pad_image(img)\n","    preprocess_img = preprocess_img/255;\n","    return preprocess_img"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:11.382900Z","iopub.status.busy":"2023-07-15T12:27:11.382528Z","iopub.status.idle":"2023-07-15T12:27:11.399570Z","shell.execute_reply":"2023-07-15T12:27:11.398880Z","shell.execute_reply.started":"2023-07-15T12:27:11.382863Z"},"trusted":true},"outputs":[],"source":["def infer(x_paths,y_paths,n_images=2):\n","    for i,x_image_path in enumerate(x_paths):\n","        if i == n_images:\n","            break\n","        print(f'{i+1}/{n_images} : {x_image_path}')\n","        x_img = preprocess_image(x_image_path)\n","        prediction = model.predict(np.expand_dims(x_img,axis=0),verbose=0)\n","\n","        y_img_path = y_paths[i]\n","        y_img = preprocess_image(y_img_path)\n","\n","        fig, ax = plt.subplots(ncols=3, figsize=(15,10));\n","        ax[0].imshow(x_img);\n","        ax[1].imshow(prediction[0]);\n","        ax[2].imshow(y_img);\n","        ax[0].axis('off');\n","        ax[1].axis('off');\n","        ax[2].axis('off');\n","        ax[0].set_title(\"Noisy Image\")\n","        ax[1].set_title(\"Predicted Image\")\n","        ax[2].set_title(\"Ground Truth Image\")\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:11.401087Z","iopub.status.busy":"2023-07-15T12:27:11.400754Z","iopub.status.idle":"2023-07-15T12:27:11.413165Z","shell.execute_reply":"2023-07-15T12:27:11.412387Z","shell.execute_reply.started":"2023-07-15T12:27:11.401053Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras import callbacks\n","class PredictionCallback(callbacks.Callback):\n","    def __init__(self, log_interval, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        #self.image_files = image_files\n","        self.log_interval = log_interval\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        if epoch % self.log_interval == 0:\n","            infer(train_x_paths,train_y_paths,n_images=2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:11.414816Z","iopub.status.busy":"2023-07-15T12:27:11.414481Z","iopub.status.idle":"2023-07-15T12:27:11.443386Z","shell.execute_reply":"2023-07-15T12:27:11.442604Z","shell.execute_reply.started":"2023-07-15T12:27:11.414784Z"},"trusted":true},"outputs":[],"source":["#model.compile(optimizer,loss, metrics = [charbonnier_loss,psnr_loss_fn,ssim_loss_fn])\n","model.compile(optimizer,charbonnier_loss, metrics = [MSEloss,psnr_loss_fn,ssim_loss_fn])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:11.445067Z","iopub.status.busy":"2023-07-15T12:27:11.444727Z","iopub.status.idle":"2023-07-15T12:27:11.451118Z","shell.execute_reply":"2023-07-15T12:27:11.450368Z","shell.execute_reply.started":"2023-07-15T12:27:11.445033Z"},"trusted":true},"outputs":[],"source":["LOG_INTERVALS = 5\n","EPOCHS = 50"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-15T12:27:11.452761Z","iopub.status.busy":"2023-07-15T12:27:11.452421Z","iopub.status.idle":"2023-07-15T14:17:50.622031Z","shell.execute_reply":"2023-07-15T14:17:50.618210Z","shell.execute_reply.started":"2023-07-15T12:27:11.452727Z"},"trusted":true},"outputs":[],"source":["# Train for 10 epochs\n","\n","hist = model.fit(train, epochs = EPOCHS, validation_data = val, callbacks=[tensorboard_callback,save_best_model_checkpoint,\n","                                                                        PredictionCallback(log_interval = LOG_INTERVALS)])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-15T14:17:50.625452Z","iopub.status.idle":"2023-07-15T14:17:50.627766Z","shell.execute_reply":"2023-07-15T14:17:50.627544Z","shell.execute_reply.started":"2023-07-15T14:17:50.627487Z"},"trusted":true},"outputs":[],"source":["# save weights\n","model.save(\"LLE_UNET_DENOISE.h5\")\n","\n","# save entire model\n","model.save('LLE_UNET_DENOISE')"]},{"cell_type":"markdown","metadata":{},"source":["**Loss graphs**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-15T14:17:50.631560Z","iopub.status.idle":"2023-07-15T14:17:50.632312Z","shell.execute_reply":"2023-07-15T14:17:50.632103Z","shell.execute_reply.started":"2023-07-15T14:17:50.632079Z"},"trusted":true},"outputs":[],"source":["plt.plot(hist.history['loss'], color='teal', label='loss')\n","plt.plot(hist.history['val_loss'], color='orange', label='val loss')\n","plt.suptitle('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**Tensorboard**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-15T14:17:50.636596Z","iopub.status.idle":"2023-07-15T14:17:50.637344Z","shell.execute_reply":"2023-07-15T14:17:50.637132Z","shell.execute_reply.started":"2023-07-15T14:17:50.637108Z"},"trusted":true},"outputs":[],"source":["%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-15T14:17:50.638664Z","iopub.status.idle":"2023-07-15T14:17:50.639397Z","shell.execute_reply":"2023-07-15T14:17:50.639186Z","shell.execute_reply.started":"2023-07-15T14:17:50.639162Z"},"trusted":true},"outputs":[],"source":["%tensorboard --logdir '/kaggle/working/logs'"]},{"cell_type":"markdown","metadata":{},"source":["**Model Inference**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-15T14:17:50.649584Z","iopub.status.idle":"2023-07-15T14:17:50.650310Z","shell.execute_reply":"2023-07-15T14:17:50.650101Z","shell.execute_reply.started":"2023-07-15T14:17:50.650078Z"},"trusted":true},"outputs":[],"source":["# on test images\n","infer(test_x_paths,test_y_paths,n_images=10)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
